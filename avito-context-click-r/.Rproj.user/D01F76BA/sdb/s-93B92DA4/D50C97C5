{
    "contents" : "#############################################################\n# train model\n#############################################################\n\nwk.seed <- 5471887\nfn.register.wk(1, seed=wk.seed)\ndata.l1.xgb.05.pred.tmp <- foreach(\n  test.type=c(\"test\"), .combine=rbind, .noexport=all.noexport) %dopar% {\n  \n  fn.init.new.fold.worker(\"l1_xgb_05\", paste0(test.type, \"2\"))\n  # fn.clean.worker()\n  \n  cat(\"\\n\\nSeed:\", wk.seed, \"...\\n\")\n  \n\n  data.tr <- xgb.DMatrix(fn.libsvm.file(\n    paste0(\"data.\", test.type, \".tr.full.libsvm\")))\n  data.test <- xgb.DMatrix(fn.libsvm.file(\n    paste0(\"data.\", test.type, \".tt.full.libsvm\")))\n  \n  eval_metric = \"logloss\"\n  data.watch = list(val=data.test)\n  if (test.type == \"val\") {\n    eval_metric <- function(preds, dtrain) {\n      labels <- as.numeric(getinfo(dtrain, \"label\"))\n      preds - as.numeric(preds)\n      err <- round(fn.log.loss(actual=labels, pred=preds), digits=5)\n      return(list(metric = \"logloss\", value = err))\n    }\n  } \n  \n  data.fold$test.pred <- data.table(\n    ID = sort(data.all.search.small[SearchType == test.type, ID]),\n    Pred = 0.0,\n    n = 0\n  )\n  \n  fn.soar.unload(data.all.search.small)\n  \n  # Num rounds 66\n  # Eta 0,5\n  # Maxdepth 10\n  # Colsample 0,375\n  # Minchildweight 10\n\n  data.fold$params = list(\n    objective = \"binary:logistic\",\n    eval_metric = eval_metric,\n    nthread = 6,\n    eta = 0.18,\n    max_depth = 10,\n    gamma = 0.8, \n    colsample_bytree = 0.7, \n    min_child_weight = 5,\n    colsample_bylevel = 0.8\n  )\n  \n  data.fold$nrounds <- 75\n  \n  cat(\"\\nParams:\\n\")\n  print(data.fold$params)\n  \n  n.models <- 10\n  for (ix in 1:n.models) {\n    \n    cat(\"\\n\\nTraining \", ix, \"of\", n.models,\"...\\n\")\n    \n    set.seed(ix + 89475560)\n    \n    model =  xgb.train(\n      data = data.tr,\n      watchlist=data.watch,\n      params = data.fold$params,\n      nrounds = data.fold$nrounds,\n      verbose = 1)\n    \n    \n    ntreelimit <- data.fold$nrounds\n    try.pred <- T\n    \n    while (try.pred) {\n      pred.cur <- xgboost::predict(model, data.test, ntreelimit=ntreelimit)\n      pred.cur.avg <- mean(pred.cur)\n      \n      cat(\"\\nCurrent prediction avg of\", length(pred.cur),\n          \"instances:\", pred.cur.avg, \"\\n\")\n      if (test.type == \"val\" || \n          (pred.cur.avg >= 0.006 && pred.cur.avg <= 0.016)) {\n        \n        try.pred <- F\n        data.fold$test.pred[ , Pred := (Pred*n + pred.cur)/(n+1)]\n        data.fold$test.pred[,  n := n+1]\n\n        \n        fn.save.data.fold(data.fold)\n        cat(\"\\nPrediction with\", ntreelimit ,\"trees included\\n\")\n      } else {\n        cat(\"\\nPrediction with\", ntreelimit ,\"trees discarded\\n\")\n        ntreelimit <- ntreelimit - 5\n        try.pred <- ntreelimit >= 60\n      }\n    }\n\n    cat(\"\\nPrediction status using\", data.fold$test.pred$n[1], \"iteration(s) :\\n\")\n    fn.print.err(data.fold$test.pred)\n\n    set.seed(Sys.time())\n    rm(pred.cur, pred.cur.avg)\n    invisible(gc())\n    \n  }\n\n#   cat(\"\\n\\nFeature importance:\\n\") \n#   data.fold$importance <- xgb.importance(\n#     feature_names=cols.in.combine, model=model)\n#   print(data.fold$importance)\n  \n  fn.clean.worker()\n  \n  data.fold$test.pred\n  \n}\nfn.kill.wk()\n\ndata.l1.xgb.05.pred.tmp <- data.l1.xgb.05.pred.tmp[order(ID)]\nStore(data.l1.xgb.05.pred.tmp)\n\nfor (ix in \"2\") {\n  test.type <- \"test\"\n  cat(\"\\nLoading\",test.type, ix,\"...\\n\")\n  \n  fn.init.fold.worker(\"l1_xgb_05\", paste0(test.type, ix), no.log=T)\n  pred.nam <- paste(\"data.l1.xgb.05.pred\", test.type, ix, sep=\".\")\n  assign(pred.nam, data.fold$test.pred[order(ID)])\n  cat(\"Saving\",pred.nam,\"...\\n\")\n  Store(list=pred.nam)\n}\n\ndata.l1.xgb.05.pred.tmp <- rbind(\n  data.l1.xgb.05.pred.test.2\n)[order(ID), list(Pred=sum(Pred*n)/sum(n)), by=\"ID\"]\n\n\ndata.l1.xgb.05.pred <- copy(data.l1.xgb.05.pred.tmp)\n\n#############################################################\n# save data\n#############################################################\n\n# fn.print.err(data.l1.xgb.05.pred)\n\n\nStore(data.l1.xgb.05.pred) #  0.04076\n\ncat('Test avg:', mean(data.l1.xgb.05.pred[ID > 0]$Pred), \"\\n\") \n# Test avg: 0.007848369\n\n# fn.write.submission(data.l1.xgb.05.pred, \"data.l1.xgb.05.pred\")\n\n\n",
    "created" : 1439614039847.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3345925690",
    "id" : "D50C97C5",
    "lastKnownWriteTime" : 1439614062,
    "path" : "~/Documents/eclipse/AvitoContext2015/final_model/avito-context-click-r/train.l1.xgb.05.R",
    "project_path" : "train.l1.xgb.05.R",
    "properties" : {
    },
    "source_on_save" : false,
    "type" : "r_source"
}